# Upload Resolution API - Complete Pipeline Overview

## ğŸ”„ Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PDF Upload Request                        â”‚
â”‚                  POST /bluelines/resolution/upload               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Step 1: Text Extraction                        â”‚
â”‚  â€¢ Uses PyMuPDF (fitz) to extract text from PDF                 â”‚
â”‚  â€¢ Removes common footer text                                   â”‚
â”‚  â€¢ Returns raw text content                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Step 2: Text Chunking                          â”‚
â”‚  â€¢ RecursiveCharacterTextSplitter                               â”‚
â”‚  â€¢ Chunk size: 2500 characters                                  â”‚
â”‚  â€¢ Chunk overlap: 250 characters                                â”‚
â”‚  â€¢ Separators: \n\n, \n, ., !                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Step 3: Embed & Store Chunks (Pinecone - Temporary)       â”‚
â”‚  â€¢ OpenAI text-embedding-3-large (3072 dimensions)              â”‚
â”‚  â€¢ Batch processing (10 chunks per API call)                    â”‚
â”‚  â€¢ Store in Pinecone temporary namespace (temp_upload_{uuid})   â”‚
â”‚  â€¢ Each chunk stored with text in metadata                      â”‚
â”‚  â€¢ Purpose: Enable semantic search for metadata extraction      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Step 4: Retrieve Relevant Chunks from Pinecone          â”‚
â”‚  â€¢ Query: "Security Council resolution"                         â”‚
â”‚  â€¢ Retrieve top 15 most relevant chunks from temp namespace     â”‚
â”‚  â€¢ Extract chunk texts from metadata                            â”‚
â”‚  â€¢ Combine chunks into context for LLM                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Step 5: Extract Metadata                          â”‚
â”‚  â€¢ LLM: meta-llama/llama-4-scout-17b-16e-instruct (Groq)       â”‚
â”‚  â€¢ Input: Retrieved chunks as context                           â”‚
â”‚  â€¢ Output: Structured JSON metadata                             â”‚
â”‚    - resolution_no                                              â”‚
â”‚    - year                                                       â”‚
â”‚    - theme                                                      â”‚
â”‚    - chapter (VI or VII)                                        â”‚
â”‚    - charter_articles                                           â”‚
â”‚    - entities                                                   â”‚
â”‚    - reporting_cycle                                            â”‚
â”‚    - operative_authority                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Step 6: Generate Summaries                        â”‚
â”‚  â€¢ Process PDF in 2-page chunks                                 â”‚
â”‚  â€¢ LLM: meta-llama/llama-4-scout-17b-16e-instruct (Groq)       â”‚
â”‚  â€¢ Generate concise summary for each chunk                      â”‚
â”‚  â€¢ Combine all summaries into complete summary                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Step 7: Store in Pinecone (Permanent - Default NS)        â”‚
â”‚  â€¢ Generate embedding for complete summary                      â”‚
â”‚  â€¢ OpenAI text-embedding-3-large (3072 dimensions)              â”‚
â”‚  â€¢ Create unique ID: {filename}_{resolution_no}_{year}          â”‚
â”‚  â€¢ Store vector + metadata in Pinecone default namespace        â”‚
â”‚  â€¢ Index: Uses UNSC_INDEX_NAME from environment                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Step 8: Cleanup Temporary Namespace                â”‚
â”‚  â€¢ Delete all vectors from temp_upload_{uuid} namespace         â”‚
â”‚  â€¢ Ensures no leftover data in Pinecone                         â”‚
â”‚  â€¢ Cleanup happens even if processing fails                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Step 9: Return Response                      â”‚
â”‚  â€¢ JSON with all metadata                                       â”‚
â”‚  â€¢ Complete summary                                             â”‚
â”‚  â€¢ Pinecone vector_id                                           â”‚
â”‚  â€¢ Filename                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow

### Input
```json
POST /bluelines/resolution/upload
Content-Type: multipart/form-data

file: [PDF Binary Data]
```

### Output
```json
{
  "message": "PDF processed and stored successfully",
  "data": {
    "resolution_no": "S/RES/XXXX (YYYY)",
    "year": "YYYY",
    "theme": ["Theme1", "Theme2"],
    "chapter": "Chapter VII",
    "charter_articles": ["Article 39", "Article 41"],
    "entities": ["Entity1", "Entity2"],
    "reporting_cycle": "Details...",
    "operative_authority": "Chapter VII",
    "summary": "Complete summary...",
    "filename": "uploaded_file.pdf",
    "vector_id": "uploaded_file_S_RES_XXXX_(YYYY)_YYYY"
  }
}
```

## ğŸ”§ Technologies Used

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Web Framework** | Flask | API endpoint handling |
| **PDF Processing** | PyMuPDF (fitz) | Text extraction from PDF |
| **Text Splitting** | LangChain RecursiveCharacterTextSplitter | Intelligent text chunking |
| **Temporary Storage** | Pinecone (temp namespace) | Temporary chunk storage for metadata extraction |
| **Embeddings** | OpenAI text-embedding-3-large | Vector generation (3072 dims) |
| **LLM Processing** | Groq (Llama-4-Scout-17b) | Metadata extraction & summarization |
| **Permanent Storage** | Pinecone (default namespace) | Long-term embedding storage & retrieval |

## ğŸ¯ Key Features

âœ… **Single API Call** - Upload, process, and store in one request  
âœ… **OpenAI Embeddings** - High-quality 3072-dimensional vectors  
âœ… **Metadata Extraction** - Structured UN Security Council metadata  
âœ… **Intelligent Summarization** - Page-by-page analysis with LLM  
âœ… **Pinecone-Based Pipeline** - Uses temporary namespaces for processing  
âœ… **Auto Cleanup** - Temporary data automatically removed after processing  
âœ… **Batch Processing** - Efficient API usage with batch embedding  
âœ… **Error Handling** - Comprehensive validation and error messages  
âœ… **Concurrent Upload Safe** - UUID-based namespaces prevent conflicts  

## ğŸ”‘ Environment Variables

```env
# OpenAI (for embeddings)
OPENAI_API_KEY=sk-...

# Groq (for LLM processing)
GROQ_API_KEY=gsk_...

# Pinecone (for vector storage)
PINECONE_API_KEY=...
UNSC_INDEX_NAME=unsc-index
PINECONE_ENVIRONMENT=...
```

## ğŸš€ Quick Start

1. **Start the server**
   ```bash
   python run.py
   ```

2. **Upload a PDF**
   ```bash
   curl -X POST http://localhost:5001/bluelines/resolution/upload \
     -F "file=@resolution.pdf"
   ```

3. **Check health**
   ```bash
   curl http://localhost:5001/bluelines/resolution/health
   ```

## ğŸ’¡ Notes

- Temporary Pinecone namespace is created per request with unique UUID
- All chunks are stored temporarily in Pinecone for metadata extraction
- Temporary namespace is automatically deleted after successful processing
- Final summary embedding is stored in Pinecone default namespace permanently
- UUID-based namespaces allow safe concurrent uploads
- Processing time: typically 1-3 minutes depending on PDF size
- Cleanup happens even if processing fails to avoid orphaned data

